import streamlit as st
import plotly.graph_objects as go
from transformers.pipelines import pipeline
import praw
from datetime import datetime, timezone

# ------------------- PARAMETRE -------------------

MAX_COMMENTS = 200        # max kommentarer vi analyserer pr. aktie
MAX_POSTS_SCAN = 400      # hvor mange af de nyeste WSB-opslag vi tjekker titlen p√•

# Udvidede keywords pr. aktie (uppercased) ‚Äì bruges p√• TITLER
COMPANY_KEYWORDS = {
    "TSLA": [
        "TSLA", "$TSLA",
        "TESLA",
        "ELON", "MUSK", "ELON MUSK",
        "TSLAQ",
    ],
    "PLTR": [
        "PLTR", "$PLTR",
        "PALANTIR",
        "KARP", "ALEX KARP",
    ],
    "SPY": [
        "SPY", "$SPY",
        "SP500", "SP 500",
        "S&P500", "S&P 500",
        "SPX",
    ],
}

OM_METODEN_TEKST = """
**Hvad sker der bag kulissen?**

- Appen bruger en sproglig AI-model, **FinBERT**, som er tr√¶net p√• finansielt sprog
  (fx nyheder, earnings-rapporter og analytiker-kommentarer).
- For hver kommentar fra *r/WallStreetBets* laver modellen et g√¶t p√•, om tonen er  
  **positiv (bullish), negativ (bearish) eller neutral**.
- Jeg t√¶ller derefter, hvor mange kommentarer der er bullish vs. bearish, og beregner
  en netto-score:

> **Score = -100** betyder kun bearish kommentarer  
> **Score = 0** betyder lige mange bullish og bearish  
> **Score = +100** betyder kun bullish

Neutrale kommentarer t√¶ller med i fordelingen, men p√•virker ikke selve scoren.

**Vigtige begr√¶nsninger**

- FinBERT er tr√¶net p√• **seri√∏st finanssprog**, ikke p√• memes, slang og ironi fra
  *r/WallStreetBets*.  
- Det betyder, at modellen nogle gange kan misforst√• fx sarkasme, interne jokes
  eller emojis.
- Resultatet skal derfor ses som et **groft stemningsbillede**, ikke som en
  pr√¶cis sandhed om markedet eller en handelsanbefaling.

Kort sagt: Appen fors√∏ger at overs√¶tte WSB-kommentarer til et enkelt tal, der
siger noget om, om stemningen i de nyeste tr√•de om aktien mest h√¶lder til
bullish eller bearish ‚Äì men med de naturlige fejl og begr√¶nsninger, der f√∏lger
med automatiseret sprogforst√•else.
"""

# ------------------- KONFIG & TITEL -------------------

st.set_page_config(page_title="Reddit AI", layout="wide")
st.title("AI Reddit Sentiment")
st.markdown("**FinBERT analyserer live kommentarer fra *r/WallStreetBets***")

# Manuelt refresh af cache
if st.button("üîÑ Opdater data nu"):
    st.cache_data.clear()
    st.rerun()  # erstatter st.experimental_rerun()

with st.expander("Hvordan virker AI-sentimentet?"):
    st.markdown(OM_METODEN_TEKST)

# ------------------- AI-MODEL (FinBERT) -------------------

@st.cache_resource
def load_ai():
    with st.spinner("Henter AI-model... (kun f√∏rste gang)"):
        return pipeline("text-classification", model="yiyanghkust/finbert-tone")

ai = load_ai()

# ------------------- REDDIT KLIENT -------------------

@st.cache_resource
def get_reddit_client():
    return praw.Reddit(
        client_id=st.secrets["reddit"]["client_id"],
        client_secret=st.secrets["reddit"]["client_secret"],
        user_agent=st.secrets["reddit"]["user_agent"],
    )

def score_to_text(score_100: int) -> str:
    """Oms√¶tter -100..100 til kort tekst."""
    if score_100 >= 40:
        return "meget bullish"
    elif score_100 >= 15:
        return "bullish"
    elif score_100 > -15:
        return "n√¶sten neutral / blandet"
    elif score_100 > -40:
        return "bearish"
    else:
        return "meget bearish"

# ------------------- HENT & ANALYSER KOMMENTARER -------------------

@st.cache_data(ttl=300)  # cache 5 minutter
def get_reddit_sentiment(symbol: str):
    reddit = get_reddit_client()
    subreddit = reddit.subreddit("wallstreetbets")

    sym_up = symbol.upper()
    keywords = COMPANY_KEYWORDS.get(sym_up, [sym_up, f"${sym_up}"])

    comments = []          # liste af (text, title)
    posts_used_ids = set()
    fetch_time = datetime.now(timezone.utc)

    blocked_phrases = [
        "User Report",
        "Total Submissions",
        "First Seen In WSB",
        "Report generated",
        "moderator of this subreddit",
    ]

    try:
        # 1) G√• igennem de nyeste WSB-opslag (ikke s√∏geindeks)
        for submission in subreddit.new(limit=MAX_POSTS_SCAN):
            title_up = submission.title.upper()
            # Kun tr√•de hvor titlen matcher et keyword
            if not any(kw in title_up for kw in keywords):
                continue

            posts_used_ids.add(submission.id)

            # Hent alle kommentarer i den tr√•d
            submission.comments.replace_more(limit=0)
            for c in submission.comments.list():
                try:
                    text = c.body
                except Exception:
                    continue

                # Filtr√©r tydeligt junk
                if len(text) < 10 or len(text) > 800:
                    continue
                if any(bad in text for bad in blocked_phrases):
                    continue

                # Vi kr√¶ver ikke keywords i kommentaren ‚Äì tr√•den handler om aktien
                comments.append((text, submission.title))

                if len(comments) >= MAX_COMMENTS:
                    break
            if len(comments) >= MAX_COMMENTS:
                break

        raw_comments_count = len(comments)
        posts_used = len(posts_used_ids)

        if raw_comments_count == 0:
            return (
                0,
                "Ingen kommentarer fundet i nylige WSB-opslag om denne aktie",
                None,
                None,
                0,
                0,
                0,
                0,
                posts_used,
                raw_comments_count,
                fetch_time,
            )

        analyzed = []  # (text, title, sentiment_word, conf)

        # 2) K√∏r FinBERT p√• ALLE kommentarer i de valgte tr√•de
        for text, title in comments:
            try:
                result = ai(text)[0]
                label = result["label"].lower()  # "positive", "negative", "neutral"
                conf = result["score"]

                if label == "positive":
                    sentiment_word = "Bullish"
                elif label == "negative":
                    sentiment_word = "Bearish"
                else:
                    sentiment_word = "Neutral"

                analyzed.append((text, title, sentiment_word, conf))
            except Exception:
                continue

        if not analyzed:
            return (
                0,
                "Kunne ikke analysere kommentarer lige nu",
                None,
                None,
                0,
                0,
                0,
                0,
                posts_used,
                raw_comments_count,
                fetch_time,
            )

        # 3) T√¶l bullish / bearish / neutral
        n_bull = sum(1 for _, _, s, _ in analyzed if s == "Bullish")
        n_bear = sum(1 for _, _, s, _ in analyzed if s == "Bearish")
        n_neutral = sum(1 for _, _, s, _ in analyzed if s == "Neutral")
        n_total = n_bull + n_bear + n_neutral

        if n_bull + n_bear > 0:
            score_100 = round(100 * (n_bull - n_bear) / (n_bull + n_bear))
        else:
            score_100 = 0

        # 4) Find bedste bullish og bedste bearish eksempel
        bull_candidates = [item for item in analyzed if item[2] == "Bullish"]
        bear_candidates = [item for item in analyzed if item[2] == "Bearish"]

        bull_example = max(bull_candidates, key=lambda x: x[3]) if bull_candidates else None
        bear_example = max(bear_candidates, key=lambda x: x[3]) if bear_candidates else None

        return (
            score_100,
            None,
            bull_example,
            bear_example,
            n_total,
            n_bull,
            n_bear,
            n_neutral,
            posts_used,
            raw_comments_count,
            fetch_time,
        )

    except Exception as e:
        return (
            0,
            f"Reddit fejl: {str(e)[:120]}",
            None,
            None,
            0,
            0,
            0,
            0,
            len(posts_used_ids),
            len(comments),
            fetch_time,
        )

# ------------------- AKTIER I DASHBOARD -------------------

stocks = ["TSLA", "PLTR", "SPY"]
names = ["Tesla", "Palantir", "S&P 500 (SPY)"]

# Hent data til alle aktier med progress bar
results = {}
progress = st.progress(0, text="Indl√¶ser data fra Reddit...")

for i, symbol in enumerate(stocks):
    results[symbol] = get_reddit_sentiment(symbol)
    progress.progress((i + 1) / len(stocks), text=f"Indl√¶ser {symbol} ({i+1}/{len(stocks)})")

progress.empty()

# ------------------- RAD 1: 3 GAUGES P√Ö STRIBE -------------------

st.subheader("WallStreetBets-sentiment (nyeste tr√•de om aktien)")

cols = st.columns(3)

for col, (name, symbol) in zip(cols, zip(names, stocks)):
    (
        score_100,
        error_msg,
        bull_ex,
        bear_ex,
        n_total,
        n_bull,
        n_bear,
        n_neutral,
        posts_used,
        raw_comments_count,
        fetch_time,
    ) = results[symbol]

    with col:
        st.markdown(f"### {name} (`{symbol}`)")

        if error_msg:
            st.info(error_msg)
        else:
            sentiment_text = score_to_text(score_100)
            st.markdown(
                f"**WSB er {sentiment_text} p√• `{symbol}` lige nu.**  \n"
                f"Score: **{score_100}** (‚àí100 bearish, 0 neutral, +100 bullish)."
            )

            fig = go.Figure(
                go.Indicator(
                    mode="gauge+number",
                    value=score_100,
                    title={"text": "Netto-bullish sentiment"},
                    gauge={
                        "axis": {"range": [-100, 100]},
                        "bar": {
                            "color": "lime"
                            if score_100 > 10
                            else "red"
                            if score_100 < -10
                            else "gray"
                        },
                    },
                )
            )
            st.plotly_chart(fig, width="stretch", key=f"gauge_{symbol}")

            last_updated = fetch_time.strftime("%Y-%m-%d %H:%M UTC")
            st.caption(
                f"Sidst opdateret: **{last_updated}** ¬∑ "
                f"{n_total} analyserede kommentarer (ud af {raw_comments_count}) "
                f"fra **{posts_used} nylige WSB-opslag**, hvor titlen n√¶vner aktien "
                f"(tjekket blandt de {MAX_POSTS_SCAN} nyeste opslag)."
            )
            st.caption(
                f"Fordeling: üêÇ {n_bull} bullish ¬∑ üêª {n_bear} bearish ¬∑ üò∂ {n_neutral} neutrale."
            )

# ------------------- RAD 2: EKSEMPLER P√Ö KOMMENTARER -------------------

st.subheader("Eksempler p√• kommentarer (AI-udvalgt)")

for name, symbol in zip(names, stocks):
    (
        score_100,
        error_msg,
        bull_ex,
        bear_ex,
        n_total,
        n_bull,
        n_bear,
        n_neutral,
        posts_used,
        raw_comments_count,
        fetch_time,
    ) = results[symbol]

    with st.expander(f"{name} (`{symbol}`)"):
        if error_msg:
            st.info(error_msg)
            continue

        if bull_ex:
            text, title, _, conf = bull_ex
            st.markdown("#### üêÇ Bullish eksempel")
            st.caption(f"Fra opslaget: *{title}*")
            st.caption(f"Model-sikkerhed: {conf:.2f}")
            st.write(text)
        else:
            st.info("Ingen tydeligt bullish kommentar fundet lige nu.")
        st.markdown("---")
        if bear_ex:
            text, title, _, conf = bear_ex
            st.markdown("#### üêª Bearish eksempel")
            st.caption(f"Fra opslaget: *{title}*")
            st.caption(f"Model-sikkerhed: {conf:.2f}")
            st.write(text)
        else:
            st.info("Ingen tydeligt bearish kommentar fundet lige nu.")
